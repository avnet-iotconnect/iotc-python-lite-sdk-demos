# Technical White Paper: PolarFire SoC TinyML Expansion Demo Stack

## 1. Purpose and Scope

This document is the single technical reference for the three expansion demos:

- `ml-classifier`
- `ml-tiny-nn-accelerator`
- `ml-complex-accelerator`

It explains, from a coding and implementation perspective:

- how synthetic input waveforms are generated
- how each classifier model is implemented in C/C++
- how SmartHLS synthesizes accelerator C/C++ into RTL (`.v`/`.vhd`)
- where integration scripts and generated HDL files are located
- how software and hardware implementations are tested and benchmarked

---

## 2. System-Level Context

The three expansion demos run the same end-to-end architecture: `/IOTCONNECT` sends commands to a Linux application on the PolarFire SoC processor complex, and that application executes either CPU inference or FPGA-accelerated inference, then publishes telemetry back to cloud dashboards.

<img src="images/polarfire-soc-bd.jpg" alt="PolarFire SoC architecture overview" width="860" />

The SoC-level view above is useful for understanding partitioning: the RISC-V processor subsystem handles Linux, networking, command parsing, and telemetry, while the FPGA fabric handles deterministic compute kernels synthesized from SmartHLS C/C++.

<img src="images/top-level.jpg" alt="PolarFire Discovery Kit top-level block view" width="760" />

The project top-level view above is the concrete workshop design integration point in Libero: accelerator RTL is inserted into the existing reference design and connected through AXI/FIC interconnect paths so Linux software can invoke it.

### 2.1 Runtime Control Plane (Cloud to App)

1. `/IOTCONNECT` command arrives (e.g. `classify`, `bench`, `status`, `led`, `load`).
2. `src/app.py` parses command arguments, validates mode/batch/seed/class, and selects operation flow.
3. `src/ml_runner.py` launches the selected ELF and parses its stdout into telemetry fields.
4. App publishes result telemetry (`ml_classify`, `ml_classify_batch`, `ml_bench`, etc.).

### 2.2 Data Plane (CPU-Only vs Fabric-Accelerated)

- **SW path (`*.no_accel.elf`)**: waveform generation + inference execute entirely on RISC-V cores.
- **HW path (`*.accel.elf`)**: software still performs orchestration, but inference kernel execution is offloaded to FPGA fabric logic generated by SmartHLS.

In both paths, the same synthetic-input definition and output schema are used, so results can be compared directly for correctness and performance.

### 2.3 Fabric Integration Model Used in All Demos

- SmartHLS compiles C/C++ accelerator code to RTL (`.v`/`.vhd`).
- Generated integration Tcl (`shls_integrate_accels.tcl`) instantiates and wires accelerator cores.
- `pre_hls_integration.tcl` normalizes project prerequisites (interconnect/core setup).
- Libero synthesis/place-route produces the job file used by FlashPro.

This is why the demos support two modes:

- **Quickstart**: consume prebuilt `.job` + prebuilt ELFs.
- **Developer flow**: regenerate HLS/RTL/ELFs and rebuild fabric.

### 2.4 Responsibility Split by System Block

| System Block | Role |
|---|---|
| `/IOTCONNECT` cloud | Command source and telemetry sink |
| Python app (`app.py`) | Command parser, job control, telemetry formatting |
| ELF runtime (`ml_runner.py` + `*.elf`) | Deterministic inference execution and timing output |
| RISC-V/Linux subsystem | OS, networking, process launch, SW inference execution |
| FPGA fabric accelerator | Offloaded inference kernel for HW mode |
| AXI/FIC interconnect | Transport/control path between processor and accelerator |

### 2.5 Why This Context Matters for Benchmark Interpretation

Single-inference latency includes fixed software/orchestration overhead (process launch, interface setup). Batch inference amortizes this overhead and better exposes accelerator throughput. This is the key reason the Complex Neural Network Accelerator emphasizes batch-aware inference and shows clearer HW advantage than simpler kernels.

---

## 3. Repository Structure and Canonical Source Locations

### 3.1 Demo-specific source of truth

| Demo | SmartHLS C/C++ model source | SmartHLS config/make | Runtime app and benchmark control |
|---|---|---|---|
| Machine Learning Classifier | `ml-classifier/assets/smarthls-module/invert_and_threshold/main_variations/main.fifo.cpp` | `ml-classifier/assets/smarthls-module/invert_and_threshold/Makefile`, `config.tcl` | `ml-classifier/src/app.py`, `src/ml_runner.py` |
| Tiny Neural Network Accelerator | `ml-tiny-nn-accelerator/assets/smarthls-module/tinyml_nn/main_variations/main.fifo.cpp` | `ml-tiny-nn-accelerator/assets/smarthls-module/tinyml_nn/Makefile`, `config.tcl` | `ml-tiny-nn-accelerator/src/app.py`, `src/ml_runner.py` |
| Complex Neural Network Accelerator | `ml-complex-accelerator/assets/smarthls-module/tinyml_complex/main_variations/main.fifo.cpp` | `ml-complex-accelerator/assets/smarthls-module/tinyml_complex/Makefile`, `config.tcl` | `ml-complex-accelerator/src/app.py`, `src/ml_runner.py` |

### 3.2 FPGA integration and generated RTL locations

| Artifact Type | Machine Learning Classifier | Tiny Neural Network Accelerator | Complex Neural Network Accelerator |
|---|---|---|---|
| Pre-integration Tcl | `ml-classifier/assets/fpga-source/pre_hls_integration.tcl` | `ml-tiny-nn-accelerator/assets/fpga-source/pre_hls_integration.tcl` | `ml-complex-accelerator/assets/fpga-source/pre_hls_integration.tcl` |
| Accel integration Tcl | `ml-classifier/assets/fpga-source/invert_and_threshold/hls_output/scripts/shls_integrate_accels.tcl` | `ml-tiny-nn-accelerator/assets/fpga-source/tinyml_nn/hls_output/scripts/shls_integrate_accels.tcl` | `ml-complex-accelerator/assets/fpga-source/tinyml_complex/hls_output/scripts/shls_integrate_accels.tcl` |
| Generated Verilog | `ml-classifier/assets/fpga-source/invert_and_threshold/hls_output/rtl/invert_and_threshold_tinyml_accel.v` | `ml-tiny-nn-accelerator/assets/fpga-source/tinyml_nn/hls_output/rtl/tinyml_nn_tinyml_accel.v` | `ml-complex-accelerator/assets/fpga-source/tinyml_complex/hls_output/rtl/tinyml_complex_tinyml_accel.v` |
| Generated VHDL | `ml-classifier/assets/fpga-source/invert_and_threshold/hls_output/rtl/invert_and_threshold_tinyml_accel.vhd` | `ml-tiny-nn-accelerator/assets/fpga-source/tinyml_nn/hls_output/rtl/tinyml_nn_tinyml_accel.vhd` | `ml-complex-accelerator/assets/fpga-source/tinyml_complex/hls_output/rtl/tinyml_complex_tinyml_accel.vhd` |
| Cycle counter RTL | `ml-classifier/assets/fpga-source/invert_and_threshold/hls_output/rtl/invert_and_threshold_soc_cycle_counter.v` | `ml-tiny-nn-accelerator/assets/fpga-source/tinyml_nn/hls_output/rtl/tinyml_nn_soc_cycle_counter.v` | `ml-complex-accelerator/assets/fpga-source/tinyml_complex/hls_output/rtl/tinyml_complex_soc_cycle_counter.v` |
| Memory init files | n/a | `ml-tiny-nn-accelerator/assets/fpga-source/tinyml_nn/hls_output/rtl/mem_init/*.mem` | `ml-complex-accelerator/assets/fpga-source/tinyml_complex/hls_output/rtl/mem_init/*.mem` |

### 3.3 Programming and implementation artifacts

- FlashPro programming jobs: `*/assets/fpga-job/MPFS_DISCOVERY_KIT.job`
- Fit/timing/utilization reports: `*/assets/fpga-job/reports/`
- Runtime ELFs deployed on Linux target: `*/src/runtimes/*.elf`

---

## 4. Input Synthesis: How Test Data Is Generated

Before any classifier logic runs, each track generates deterministic synthetic waveforms in C/C++ using:

- class ID (`input_class`)
- seed (`seed`)
- fixed sample length (`N_SAMPLES`)
- additive pseudo-random noise from an LCG

This is why test runs are reproducible for a given `(class, seed)` pair.

### 4.1 Common generator pattern

1. Select class-specific base waveform function.
2. Compute sample-by-sample signal for 256 samples.
3. Add bounded noise from linear congruential generator (LCG).
4. Clamp to `int16_t`.

### 4.2 Waveform primitives used across tracks

<p>
  <img src="images/triangle_wave.svg" alt="Triangle waveform" width="180" />
  <img src="images/square_wave.svg" alt="Square waveform" width="180" />
  <img src="images/sawtooth_wave.svg" alt="Saw waveform" width="180" />
</p>

### 4.3 Demo-specific synthetic classes

| Demo | Classes | Representative waveform composition |
|---|---|---|
| Machine Learning Classifier | 3 | triangle, mixed triangle frequencies, burst+triangle |
| Tiny Neural Network Accelerator | 6 | triangle, mixed frequencies, burst, square, chirp, impulse-train |
| Complex Neural Network Accelerator | 6 | richer combinations: triangle+saw, burst trains, damped ringing, impulse+saw |

Complex Neural Network training and inference use the same waveform family definition (`gen_signal`) to keep deployment behavior aligned with training assumptions.

### 4.4 Waveform galleries

#### Machine Learning Classifier

<p>
  <img src="images/classifier-waveforms/classifier_class0.svg" alt="Machine Learning Classifier class 0 waveform" width="280" />
  <img src="images/classifier-waveforms/classifier_class1.svg" alt="Machine Learning Classifier class 1 waveform" width="280" />
</p>
<p>
  <img src="images/classifier-waveforms/classifier_class2.svg" alt="Machine Learning Classifier class 2 waveform" width="280" />
  <img src="images/classifier-waveforms/classifier_class3.svg" alt="Machine Learning Classifier class 3 waveform" width="280" />
</p>
<p>
  <img src="images/classifier-waveforms/classifier_class4.svg" alt="Machine Learning Classifier class 4 waveform" width="280" />
  <img src="images/classifier-waveforms/classifier_class5.svg" alt="Machine Learning Classifier class 5 waveform" width="280" />
</p>

#### Tiny Neural Network Accelerator

<p>
  <img src="images/nn-waveforms/nn_class0.svg" alt="Tiny Neural Network class 0 waveform" width="280" />
  <img src="images/nn-waveforms/nn_class1.svg" alt="Tiny Neural Network class 1 waveform" width="280" />
</p>
<p>
  <img src="images/nn-waveforms/nn_class2.svg" alt="Tiny Neural Network class 2 waveform" width="280" />
  <img src="images/nn-waveforms/nn_class3.svg" alt="Tiny Neural Network class 3 waveform" width="280" />
</p>
<p>
  <img src="images/nn-waveforms/nn_class4.svg" alt="Tiny Neural Network class 4 waveform" width="280" />
  <img src="images/nn-waveforms/nn_class5.svg" alt="Tiny Neural Network class 5 waveform" width="280" />
</p>

#### Complex Neural Network Accelerator

<p>
  <img src="images/complex-waveforms/complex_class0.svg" alt="Complex Neural Network class 0 waveform" width="280" />
  <img src="images/complex-waveforms/complex_class1.svg" alt="Complex Neural Network class 1 waveform" width="280" />
</p>
<p>
  <img src="images/complex-waveforms/complex_class2.svg" alt="Complex Neural Network class 2 waveform" width="280" />
  <img src="images/complex-waveforms/complex_class3.svg" alt="Complex Neural Network class 3 waveform" width="280" />
</p>
<p>
  <img src="images/complex-waveforms/complex_class4.svg" alt="Complex Neural Network class 4 waveform" width="280" />
  <img src="images/complex-waveforms/complex_class5.svg" alt="Complex Neural Network class 5 waveform" width="280" />
</p>

---

## 5. Classification/Inference Methods by Demo

<img src="images/classification_methods.svg" alt="Classification methods comparison" width="900" />

### 5.1 Machine Learning Classifier: Template-Correlation (Deterministic Baseline)

Implementation file:

- `ml-classifier/assets/smarthls-module/invert_and_threshold/main_variations/main.fifo.cpp`

Core operation:

- `score[c] = sum_i(input[i] * template_wave(i, c))`
- `pred = argmax(score)`

Characteristics:

- simple matched-filter style classifier
- minimal compute depth
- useful to validate cloud, command, and telemetry pipeline quickly

### 5.2 Tiny Neural Network Accelerator: Compact Fixed-Point NN-Style Classifier

Implementation file:

- `ml-tiny-nn-accelerator/assets/smarthls-module/tinyml_nn/main_variations/main.fifo.cpp`

Pipeline:

1. Feature extraction (`N_FEATURES=32`) by block averaging.
2. Layer-1 projection vs class templates (`W1_POS`) with ReLU and sign split.
3. Layer-2 linear scoring per class.
4. `argmax` classification.

Characteristics:

- true neural network-style multi-stage integer pipeline
- still relatively small, so SW/HW speed delta is modest at low batch

### 5.3 Complex Neural Network Accelerator: Deeper NN with Batch-Aware Interface

Implementation files:

- Inference: `ml-complex-accelerator/assets/smarthls-module/tinyml_complex/main_variations/main.fifo.cpp`
- Exported weights: `ml-complex-accelerator/assets/smarthls-module/tinyml_complex/main_variations/model_weights.h`
- Training/export tool: `ml-complex-accelerator/tools/train_and_export_complex.py`

Network shape:

- input: 256 samples
- features: 64 engineered features
- hidden1: 96
- hidden2: 48
- output classes: 6

Key implementation detail:

- top function supports batch (`batch_n`) with DMA interfaces and loops over `tinyml_accel_single`.

This increases arithmetic intensity and amortizes offload overhead, which is where HW acceleration becomes more visible.

---

## 6. Complex Neural Network Training and Weight Export Flow

The Complex Neural Network Accelerator includes an explicit training/export stage.

Script:

- `ml-complex-accelerator/tools/train_and_export_complex.py`

What it does:

1. Generates synthetic train/eval datasets using the same waveform generator logic.
2. Applies fixed feature extractor + fixed hidden layers (`W1/W2`, deterministic functions).
3. Trains classifier head (`W3/B3`) with integer perceptron-style updates.
4. Exports `model_weights.h` consumed by SmartHLS C++ model.

Important outputs:

- `model_weights.h` includes accuracy metadata comments and quantization shifts.
- Header is compiled into both SW and HW builds, ensuring parity when integration is correct.

---

## 7. SmartHLS to HDL/Verilog Flow

### 7.1 Build commands (per module directory)

```powershell
& "C:\Microchip\Libero_SoC_2025.2\SmartHLS\SmartHLS\bin\shls.bat" -a soc_sw_compile_no_accel
& "C:\Microchip\Libero_SoC_2025.2\SmartHLS\SmartHLS\bin\shls.bat" -a soc_sw_compile_accel
```

Run from one of:

- `<REFERENCE_DESIGN_ROOT>/script_support/additional_configurations/smarthls/invert_and_threshold/` (Machine Learning Classifier)
- `<REFERENCE_DESIGN_ROOT>/script_support/additional_configurations/smarthls/tinyml_nn/` (Tiny Neural Network Accelerator)
- `<REFERENCE_DESIGN_ROOT>/script_support/additional_configurations/smarthls/tinyml_complex/` (Complex Neural Network Accelerator)

### 7.2 Generated outputs

- SW-only ELF: `hls_output/*.no_accel.elf`
- HW-accelerated ELF: `hls_output/*.accel.elf`
- RTL: `hls_output/rtl/*.v`, `*.vhd`
- Libero integration Tcl: `hls_output/scripts/shls_integrate_accels.tcl`
- Libero HDL-create Tcl scripts: `hls_output/scripts/libero/create_hdl_plus*.tcl`

### 7.3 Libero integration scripts

Run in Libero (with project root set correctly):

1. `script_support/additional_configurations/smarthls/pre_hls_integration.tcl`
2. `script_support/additional_configurations/smarthls/<module>/hls_output/scripts/shls_integrate_accels.tcl`

Where `<module>` is one of:

- `invert_and_threshold`
- `tinyml_nn`
- `tinyml_complex`

---

## 8. FPGA Fabric Composition Across Demos

<img src="images/fpga_internal_logic.svg" alt="Internal FPGA logic by demo" width="900" />

Common pattern:

- AXI interconnect and bridge logic
- SmartHLS accelerator core (`tinyml_accel_top`)
- cycle counter/auxiliary support logic
- DMA/AXI initiator path used by accelerated ELF

Differences by demo are primarily in accelerator complexity (operator count, memory init usage, and interface behavior such as batch DMA).

---

## 9. Software Verification and Benchmark Methodology

### 9.1 Local ELF parity check (on board)

```bash
./runtimes/<track>.no_accel.elf <class> <seed> [batch]
./runtimes/<track>.accel.elf <class> <seed> [batch]
```

Expected check points:

- same predicted class (`pred`) for SW vs HW
- similar score vectors (exact match for deterministic paths)
- HW timing vs SW timing trend aligns with complexity expectations

### 9.2 Cloud command loop (/IOTCONNECT)

Commands used in demo app:

- `classify <sw|hw> <class> <seed> [batch]`
- `bench both <class> <seed> <batch>`

Telemetry fields to compare:

- `pred`, `scores_csv`
- `time_s` (single inference)
- `sw_avg_time_s`, `hw_avg_time_s`, `speedup_sw_over_hw` (benchmark)
- `match_rate` for batched runs

### 9.3 Why HW may not always be faster

HW speedup depends on compute-to-overhead ratio:

- Small/simple models: offload setup + transfer overhead can dominate.
- Larger/deeper/batched models: arithmetic dominates, so fabric throughput wins.

Demo behavior in this repo reflects that progression:

- Machine Learning Classifier: often SW-competitive
- Tiny Neural Network Accelerator: moderate HW gain
- Complex Neural Network Accelerator: stronger and more consistent HW advantage (especially with batch)

---

## 10. End-to-End Build and Validation Flow (Code to Cloud)

```mermaid
flowchart TD
    A[Edit model C/C++ in assets/smarthls-module] --> B[Run shls.bat compile targets]
    B --> C[Generate ELFs + RTL + integration Tcl]
    C --> D[Run Libero pre_hls_integration.tcl]
    D --> E[Run shls_integrate_accels.tcl]
    E --> F[Synthesize / Place&Route / Timing]
    F --> G[Export MPFS_DISCOVERY_KIT.job]
    G --> H[Program board with FlashPro]
    H --> I[Deploy package.tar.gz to Linux target]
    I --> J[Run app.py and send classify/bench commands from /IOTCONNECT]
    J --> K[Validate parity, performance, telemetry]
```

---

## 11. Practical Guidance for Modifying Models

1. Change waveform generator and/or model code in `main.fifo.cpp`.
2. For Complex Neural Network Accelerator, regenerate `model_weights.h` with `tools/train_and_export_complex.py`.
3. Re-run SmartHLS compile targets.
4. Re-apply integration Tcl scripts in a clean Libero project.
5. Rebuild `.job` and replace runtime ELFs in demo package.
6. Re-run `classify` and `bench` parity/performance validation.

This keeps software, hardware, and cloud telemetry behavior aligned after each model revision.
